{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways from quick exploration in Excel\n",
    "\n",
    "After quickly analyzing the file in Excel, these would be my first recommendations to management:\n",
    "\n",
    "1. Take superman off the streets. He's responsible for 23 of the 30 near-misses in just one day. He also has the lowest rating. If needed, use this quote:\n",
    "\n",
    "  > Today is a day for truth. The world needs to know what happened and to know what he stands for. That kind of power is very dangerous.\n",
    "\n",
    "1. End long rides. They cost the same as short ones, but leave riders very unsatisfied. They don't like it. Most importantly, that's were near misses happen.\n",
    "\n",
    "1. Promote Hulk. Or if you had to pick just one model to mass produce, just pick Hulk. Zero near-misses, highest rating, most trips, most riders, and most revenue (by far! He brought in \\\\$514, leaving the second highest, robin, at \\\\$113 away with just above \\\\$400).\n",
    "\n",
    "    _(Uhm, Hulk is the best, and Superman is the worst. Sounds like we have an Avengers fan in the midst.)_\n",
    "\n",
    "1. Promote multiple rider \"pools\". We charge a \\\\$3 premium for 1-passenger (private) rides and that doesn't seem to discourage people from taking them or having a positive experience. And they're more lucrative than 2-rider pools. But on Oct 2nd we brought in a total of \\\\$1114 for almost 200 private rides vs. \\\\$8372 for more than 800 pools. So not only pools seem more popular, but they also bring twice as much money as private ones. The 4-rider are both particularly lucrative and have the highest rating.\n",
    "\n",
    "1. Consider limiting number of riders to 4. 5-rider trips have much lower ratings (car is packed?)\n",
    "\n",
    "1. Disregard all of the above. These are all based on just **one day** of data. Please don't make any rash decisions.\n",
    "\n",
    "Other learnings:\n",
    "\n",
    "1. Users still return after near misses. Most striking is user #7 that continued to ride, even after suffering 5 near misses in one trip with superman. The user even rode superman again. He probably didn't have a choice. The same is true for other users.\n",
    "\n",
    "1. The trips are divided in two buckets of duration: less than 30 min (aka _short trips_), and longer than one hour (_long trips_). All the near misses happen in a long trip. That's 30 near misses in 51 trips. Some trips have multiple near misses (the maximum being 5 in just one trip, by superman), and so there's 19 trips with at least one near miss. These are very high rates.\n",
    "\n",
    "1. There are multiple instances of the same car. Unless the laws of physics are being violated (or the timestamps are wrong), we must assume there is more than one superman. For example, there's a superman trip from `2018-10-02 07:12:21` to `2018-10-02 08:21:23`, and another from `2018-10-02 07:13:45` to `2018-10-02 08:32:29`. These are overlapping. More importantly, near misses happen in both these trips. So the problem is not with just one particular instance of superman, but the whole model. This happens for other cars as well.\n",
    "\n",
    "1. Prices are also divided in two buckets: \\\\$5 to \\\\$6.5 for 1 rider, and \\\\$2 to \\\\$3.5 for multiple riders (2 to 5 riders, it doesn't matter). Prices also don't seem to depend on distance. That means that total revenue is just a function of number of rides (with the exception of the 1-rider vs multiple riders price difference). We could change our pricing model to depend on distance and/or time, but riders don't seem to like long-distance rides anyway. Higher price would just make it worse!\n",
    "\n",
    "1. All cars take 1 to 5 passengers. Seems to suggest they're all the same size.\n",
    "\n",
    "1. There is an error in the timestamps. Later trips seem to travel back in time because they end in the same day, but much earlier. E.g. from `2018-10-02 23:59:36` to `2018-10-02 00:10:15`. I just assume the end date was meant to be `2018-10-03 00:10:15` instead (i.e. one day later). That's easy to fix by adding 1 day to the trip duration if the duration is negative.\n",
    "\n",
    "\n",
    "# Using python and sklearn for predictive modeling\n",
    "I usually do data exploration with python, pandas, and seaborn (for plotting). And because you probably want to evaluate my python skills, I'll do a bit of exploration here. But in the end I don't think we learned anything new that we didn't already know after exploring a bit using Excel and pivot tables.\n",
    "\n",
    "Towards the bottom of this notebook we do a tiny bit of modeling. We'll use predictive models, but the goal is not to predict or forecast. The goal is to explore the importance of some of these features. For example, we've seen that the car matters, so does the trip duration. We analyzed most features independently, but here we're looking for more nuanced relationships, that we might have missed at first glance.\n",
    "\n",
    "Finally, we should note that the sample size is very small. We add more features, but mostly are just transforms of existing ones, highly correlated. We expand the feature space a little bit, but not significantly. Again, we're not doing predictive modeling, otherwise we would worry about having too many (collinear) features. We also don't need to split the data into test and training for feature importance. Basically we're throwing out all precautions usually in place to avoid overfitting out the window just for this purpose (i.e. low sample size, feature collinearity, multi-dimensionality, no cross-validation, and class imbalance â€“ near misses are a \"rare\" event). We could do more model if we had the time, but again, probably not worth it without more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 9)\n",
      "user_id                     int64\n",
      "car_id                     object\n",
      "start_time         datetime64[ns]\n",
      "end_time           datetime64[ns]\n",
      "num_riders                  int64\n",
      "region                     object\n",
      "num_near_misses             int64\n",
      "price                     float64\n",
      "rating                      int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>car_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>num_riders</th>\n",
       "      <th>region</th>\n",
       "      <th>num_near_misses</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>spiderman</td>\n",
       "      <td>2018-10-02 03:00:21</td>\n",
       "      <td>2018-10-02 03:08:19</td>\n",
       "      <td>3</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>superman</td>\n",
       "      <td>2018-10-02 03:01:30</td>\n",
       "      <td>2018-10-02 03:09:16</td>\n",
       "      <td>2</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hulk</td>\n",
       "      <td>2018-10-02 03:01:45</td>\n",
       "      <td>2018-10-02 03:09:15</td>\n",
       "      <td>2</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>spiderman</td>\n",
       "      <td>2018-10-02 03:02:08</td>\n",
       "      <td>2018-10-02 03:15:34</td>\n",
       "      <td>3</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>scarecrow</td>\n",
       "      <td>2018-10-02 03:02:13</td>\n",
       "      <td>2018-10-02 04:02:47</td>\n",
       "      <td>4</td>\n",
       "      <td>sf</td>\n",
       "      <td>0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     car_id          start_time            end_time  num_riders  \\\n",
       "0        9  spiderman 2018-10-02 03:00:21 2018-10-02 03:08:19           3   \n",
       "1       12   superman 2018-10-02 03:01:30 2018-10-02 03:09:16           2   \n",
       "2        3       hulk 2018-10-02 03:01:45 2018-10-02 03:09:15           2   \n",
       "3       10  spiderman 2018-10-02 03:02:08 2018-10-02 03:15:34           3   \n",
       "4        9  scarecrow 2018-10-02 03:02:13 2018-10-02 04:02:47           4   \n",
       "\n",
       "  region  num_near_misses  price  rating  \n",
       "0     sf                0   3.25       5  \n",
       "1     sf                0   2.95       5  \n",
       "2     sf                0   3.22       5  \n",
       "3     sf                0   2.29       5  \n",
       "4     sf                0   2.93       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('final_analytics_takehome (1) (1) (1).xlsx')\n",
    "print (df.shape)\n",
    "print (df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>num_riders</th>\n",
       "      <th>num_near_misses</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1033.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.220716</td>\n",
       "      <td>3.100678</td>\n",
       "      <td>0.029042</td>\n",
       "      <td>3.324985</td>\n",
       "      <td>3.745402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.906874</td>\n",
       "      <td>1.445901</td>\n",
       "      <td>0.251216</td>\n",
       "      <td>1.224522</td>\n",
       "      <td>1.063871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id   num_riders  num_near_misses        price       rating\n",
       "count  1033.000000  1033.000000      1033.000000  1033.000000  1033.000000\n",
       "mean     10.220716     3.100678         0.029042     3.324985     3.745402\n",
       "std       5.906874     1.445901         0.251216     1.224522     1.063871\n",
       "min       1.000000     1.000000         0.000000     2.000000     1.000000\n",
       "25%       5.000000     2.000000         0.000000     2.490000     3.000000\n",
       "50%      10.000000     3.000000         0.000000     2.950000     3.000000\n",
       "75%      15.000000     4.000000         0.000000     3.410000     5.000000\n",
       "max      20.000000     5.000000         5.000000     6.500000     5.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip duration\n",
    "Also fixes the \"travel back in time\" issue mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = df['end_time'] - df['start_time']\n",
    "df.loc[df['duration'].dt.days < 0, 'duration'] += datetime.timedelta(days=1)\n",
    "df['duration_sec'] = df.duration.dt.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is trip short or long\n",
    "We saw the <30min vs. >1h difference above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_long'] = df['duration'] > datetime.timedelta(hours=1)\n",
    "df.drop('duration', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is pool\n",
    "More than 1-rider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_pool'] = df.num_riders > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has at least one near miss\n",
    "Just binary: did a near miss happen during this trip, to discount the ones where as much as 5 happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_near_miss'] = df.num_near_misses > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total price\n",
    "Assuming `price: the price that the rider paid to get on the ride` is per rider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_price'] = df.num_riders * df.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC vs. Marvel\n",
    "Some cars are Avengers (higher ratings), some are Justice League (lower ratings, and superman), and some are neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_avenger'] = df.car_id.isin(['hulk', 'ironman', 'spiderman', 'venom'])\n",
    "df['is_justice_league'] = df.car_id.isin(['batman', 'superman'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize ratings by user's average\n",
    "> Different rating scales. This problem is related to the fact that \"conservative\" users tend to assign items to a narrow range of rating categories whereas \"liberal\" users tend to assign items to a wide range of rating categories. To account for this factor, the ratings of each user are divided by the variance in his ratings.\n",
    "\n",
    "in Jin, Rong, and Luo Si. \"A study of methods for normalizing user ratings in collaborative filtering.\" Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df.groupby('user_id').rating.agg(['mean', 'std']), 'user_id')\n",
    "df['rating_normed'] = (df['rating'] - df['mean']) / df['std']\n",
    "df.drop(['mean', 'std'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the first 4 trips on file all have a rating of 5. But after weighting by the individual user's rating behavior, we can see that a rating of 5 by user #12 is much more meaningful than the same value rating by other users. That's because user #12 doesn't rate particular high on average (compared to other users) and also rates on a narrower range. In other words, user #12 might not give 5-star ratings as often as other users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mean       std\n",
      "user_id                    \n",
      "9        3.727273  1.245711\n",
      "12       3.777778  0.974420\n",
      "3        4.000000  1.036375\n",
      "10       3.763636  1.104932\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>car_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_normed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>spiderman</td>\n",
       "      <td>5</td>\n",
       "      <td>1.021687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>superman</td>\n",
       "      <td>5</td>\n",
       "      <td>1.254307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hulk</td>\n",
       "      <td>5</td>\n",
       "      <td>0.964901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>spiderman</td>\n",
       "      <td>5</td>\n",
       "      <td>1.118950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     car_id  rating  rating_normed\n",
       "0        9  spiderman       5       1.021687\n",
       "1       12   superman       5       1.254307\n",
       "2        3       hulk       5       0.964901\n",
       "3       10  spiderman       5       1.118950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.groupby('user_id').rating.agg(['mean', 'std']).loc[[9,12,3,10]])\n",
    "df[['user_id', 'car_id', 'rating', 'rating_normed']].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary ratings\n",
    "Good vs Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top_rating'] = df.rating >= 4\n",
    "df['bad_rating'] = df.rating <= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Night and Day\n",
    "Visibility is worst at night, but traffic could be worst during the day. Note: use just `start_time` for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "between_time = df.set_index('start_time').index.indexer_between_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[between_time('7:06','18:50'),'is_day'] = True\n",
    "df.is_day.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rush hour\n",
    "More accidents? Lower rating? Oct 2nd was a Tuesday (i.e. week-day). Note: use only `start_time` for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[np.append(between_time('7:00','9:00'), between_time('16:00','18:00')), 'is_rush_hour'] = True\n",
    "df.is_rush_hour.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_time_hour'] = df.start_time.dt.hour\n",
    "df['end_time_hour'] = df.end_time.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables\n",
    "We need to convert `user_id`, `car_id`, `region`, and dates/hours to binary. `user_id` is numerical, but it has no real meaning (e.g. user_id 7 > user_id 2 doesn't make sense). Same for hours (they're circular, as in the clock resets at midnight, and so they're not really numerical). `car_id` and `region` are categorical, so we need to encode them. And sklearn models don't work with timestamps. There's multiple ways to do that, the simplest one being adding an indicator variable for each category. The pandas library has a very simple method to do this, called [pd.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "\n",
    "NOTE: this method of encode these categorical features as binary vectors is also known as [one-hot encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['user_id', 'car_id', 'region', 'start_time_hour', 'end_time_hour']\n",
    "df = pd.concat([df, pd.get_dummies(df[cat_cols].astype(str))], axis=1)\n",
    "df.drop(cat_cols + ['start_time', 'end_time'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Variables\n",
    "As a business, we're interested in maximizing user satisfaction (`rating`), revenue (`price` or total rides), and safety (minimize `num_near_misses`). Let's define those as our dependent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear correlations\n",
    "As a first pass, we can check which features correlate with our variables of interest. Not ideal for the binary variables we just created above, but it will give us a sense of direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety\n",
    "As we identified before, long rides are associated with higher number of near misses. These are also associated with bad ratings, but it's hard to know if it's causation or just correlation (i.e. is the bad rating because of the near misses or because the ride was too long? Probably the latter â€“ see below). We've also noted how Justice League cars have a poorer safety record (mostly `superman`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_near_misses      1.000000\n",
       "has_near_miss        0.844942\n",
       "is_long              0.507523\n",
       "duration_sec         0.442549\n",
       "bad_rating           0.374386\n",
       "car_id_superman      0.257468\n",
       "is_justice_league    0.168622\n",
       "start_time_hour_9    0.133089\n",
       "end_time_hour_10     0.122517\n",
       "user_id_7            0.083013\n",
       "end_time_hour_1      0.082610\n",
       "user_id_5            0.051970\n",
       "start_time_hour_5    0.051970\n",
       "is_day               0.051914\n",
       "is_avenger          -0.087140\n",
       "top_rating          -0.114657\n",
       "rating_normed       -0.262674\n",
       "rating              -0.280487\n",
       "Name: num_near_misses, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()['num_near_misses']\n",
    "corr[corr.abs() > 0.05].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make it clear how strong the 0.5 correlation above with long rides really is, here we show again how **near misses only happen on long rides**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_long\n",
       "False     0\n",
       "True     30\n",
       "Name: num_near_misses, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('is_long').num_near_misses.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to what I was expecting, near misses seem to happen slightly more often during the day then at night, but honestly the correlation is so low that it could just be random. We can look at it another way to confirm that maybe there is something there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_day\n",
       "False    0.014831\n",
       "True     0.040998\n",
       "Name: num_near_misses, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('is_day').num_near_misses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rush hour doesn't seem to play a role in the near misses, though.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_rush_hour\n",
       "False    0.028302\n",
       "True     0.032432\n",
       "Name: num_near_misses, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('is_rush_hour').num_near_misses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note how, even though user #7 has the most number of near misses, most happened in just one trip (5). In contrast, user #17 has the most trips with at least one near miss. Regardless, I think this is just random. We would need a lot more data to conclude that the user is at fault, I believe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_near_miss        1.000000\n",
       "num_near_misses      0.844942\n",
       "is_long              0.600660\n",
       "duration_sec         0.515784\n",
       "bad_rating           0.443090\n",
       "car_id_superman      0.242998\n",
       "is_justice_league    0.160524\n",
       "end_time_hour_1      0.157864\n",
       "start_time_hour_9    0.147402\n",
       "end_time_hour_10     0.123093\n",
       "user_id_17           0.086282\n",
       "user_id_5            0.078156\n",
       "end_time_hour_8      0.075231\n",
       "start_time_hour_7    0.071132\n",
       "is_day               0.067708\n",
       "car_id_hulk         -0.058385\n",
       "is_avenger          -0.087264\n",
       "top_rating          -0.135698\n",
       "rating_normed       -0.295583\n",
       "rating              -0.319539\n",
       "Name: has_near_miss, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()['has_near_miss']\n",
    "corr[corr.abs() > 0.05].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User satisfaction \n",
    "Bad ratings come mostly from long ride times (note the associated correlation with near misses mentioned above). Avenger cars have slightly higher rating, but negligible (except `hulk`, which does seem more popular). Also slightly higher ratings for south sf compared to sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating                1.000000\n",
       "rating_normed         0.987550\n",
       "top_rating            0.900131\n",
       "car_id_hulk           0.089508\n",
       "user_id_15            0.066774\n",
       "end_time_hour_3       0.060018\n",
       "region_south sf       0.059807\n",
       "start_time_hour_20    0.059015\n",
       "price                 0.058814\n",
       "start_time_hour_21    0.057712\n",
       "user_id_3             0.056779\n",
       "is_avenger            0.055162\n",
       "end_time_hour_20      0.053339\n",
       "end_time_hour_15     -0.050766\n",
       "user_id_20           -0.052021\n",
       "end_time_hour_10     -0.056287\n",
       "region_sf            -0.059807\n",
       "is_pool              -0.060138\n",
       "is_day               -0.069758\n",
       "end_time_hour_16     -0.071218\n",
       "car_id_superman      -0.078322\n",
       "is_justice_league    -0.090285\n",
       "end_time_hour_1      -0.093004\n",
       "start_time_hour_15   -0.093602\n",
       "total_price          -0.119216\n",
       "num_riders           -0.126945\n",
       "num_near_misses      -0.280487\n",
       "has_near_miss        -0.319539\n",
       "is_long              -0.441300\n",
       "bad_rating           -0.558736\n",
       "duration_sec         -0.570826\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()['rating']\n",
    "corr[corr.abs() > 0.05].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again just making it explicit how bad ratings (2 or below) only happen on long rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad_rating\n",
       "False     0\n",
       "True     51\n",
       "Name: is_long, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('bad_rating').is_long.sum().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More riders also seems to lead to lower ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad_rating\n",
       "False    2.972428\n",
       "True     4.444444\n",
       "Name: num_riders, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('bad_rating').num_riders.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particularly we see a lot of 2-star ratings for rides with 5 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    3.000000\n",
       "2    4.756757\n",
       "3    2.958237\n",
       "4    2.851351\n",
       "5    3.038462\n",
       "Name: num_riders, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('rating').num_riders.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why we recommend to abolish those. 4-rider trips are actually the highest rated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad_rating  num_riders\n",
       "False       3             195\n",
       "            1             193\n",
       "            2             188\n",
       "            4             186\n",
       "            5             181\n",
       "True        5              69\n",
       "            3               8\n",
       "            2               6\n",
       "            4               4\n",
       "            1               3\n",
       "Name: num_riders, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('bad_rating').num_riders.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_riders\n",
       "1    3.877551\n",
       "2    3.804124\n",
       "3    3.822660\n",
       "4    3.915789\n",
       "5    3.404000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('num_riders').rating.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, notice how `user_id_15` and `user_id_20` correlate with `rating` above, but that goes way when we normalize them by user (by definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_normed         1.000000\n",
       "rating                0.987550\n",
       "top_rating            0.894602\n",
       "car_id_hulk           0.079262\n",
       "start_time_hour_20    0.066842\n",
       "region_south sf       0.062427\n",
       "start_time_hour_21    0.061604\n",
       "end_time_hour_20      0.057487\n",
       "end_time_hour_3       0.054804\n",
       "price                 0.054438\n",
       "car_id_joker          0.050860\n",
       "is_pool              -0.054014\n",
       "end_time_hour_15     -0.055230\n",
       "region_sf            -0.062427\n",
       "is_day               -0.068554\n",
       "end_time_hour_16     -0.073066\n",
       "car_id_superman      -0.074399\n",
       "is_justice_league    -0.085559\n",
       "start_time_hour_15   -0.095782\n",
       "end_time_hour_1      -0.097436\n",
       "total_price          -0.117511\n",
       "num_riders           -0.123936\n",
       "num_near_misses      -0.262674\n",
       "has_near_miss        -0.295583\n",
       "is_long              -0.430936\n",
       "bad_rating           -0.544658\n",
       "duration_sec         -0.563857\n",
       "Name: rating_normed, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()['rating_normed']\n",
    "corr[corr.abs() > 0.05].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, the region correlation (i.e. south sf having slighter ratings then sf) seems to hold. Robin also seems to drive more often in the south than sf. The opposite is true for Hulk. South sf rides are also very slightly shorter than sf, but that's probably noise (or lack of traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region_south sf       1.000000\n",
       "top_rating            0.085398\n",
       "car_id_robin          0.082018\n",
       "rating_normed         0.062427\n",
       "start_time_hour_17    0.062111\n",
       "rating                0.059807\n",
       "end_time_hour_3       0.057851\n",
       "user_id_7             0.051315\n",
       "end_time_hour_8      -0.050205\n",
       "is_long              -0.052997\n",
       "car_id_hulk          -0.062713\n",
       "duration_sec         -0.064832\n",
       "bad_rating           -0.071844\n",
       "region_sf            -1.000000\n",
       "Name: region_south sf, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()['region_south sf']\n",
    "corr[corr.abs() > 0.05].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price\n",
    "Price doesn't correlate with much besides number of riders, more concretely, with just _is pool_ or _is private_. The `bad_rating` negative correlation is because of the low rating of 5-rider pools (which correlates with `is_pool`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price              1.000000\n",
       "user_id_11         0.063046\n",
       "rating             0.058814\n",
       "rating_normed      0.054438\n",
       "user_id_14         0.050352\n",
       "duration_sec      -0.056874\n",
       "car_id_superman   -0.057057\n",
       "end_time_hour_8   -0.061311\n",
       "is_long           -0.064199\n",
       "user_id_19        -0.072564\n",
       "bad_rating        -0.104411\n",
       "total_price       -0.274264\n",
       "num_riders        -0.636697\n",
       "is_pool           -0.933252\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()['price']\n",
    "corr[corr.abs() > 0.05].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "Another (perhaps better) way to measure feature importance is to actually fit a model. We try both linear and non-linear modes, but I don't think we learn anything that we didn't know already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_pool            6958.711628\n",
       "num_riders          702.887995\n",
       "bad_rating           11.363395\n",
       "user_id_19            5.457527\n",
       "is_long               4.266840\n",
       "user_id_11            4.114307\n",
       "end_time_hour_8       3.890160\n",
       "rating                3.578733\n",
       "car_id_superman       3.367384\n",
       "duration_sec          3.345690\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "y = df.price\n",
    "X = df.drop(['price', 'total_price', 'rating_normed'], 1)\n",
    "model = SelectKBest(f_regression).fit(X, y)\n",
    "importances = model.scores_\n",
    "pd.Series(importances, X.columns).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_sec         288985.277537\n",
       "is_long                 354.297792\n",
       "bad_rating              185.138407\n",
       "car_id_superman          70.002427\n",
       "end_time_hour_1          41.551036\n",
       "start_time_hour_9        40.900721\n",
       "end_time_hour_10         32.895991\n",
       "rating                   32.047377\n",
       "is_justice_league        26.388707\n",
       "start_time_hour_5        22.275832\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.num_near_misses\n",
    "X = df.drop(['num_near_misses', 'has_near_miss', 'rating_normed'], 1)\n",
    "model = SelectKBest(chi2).fit(X, y)\n",
    "importances = model.scores_\n",
    "pd.Series(importances, X.columns).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_sec         597003.227075\n",
       "num_near_misses        1326.684966\n",
       "has_near_miss           665.380868\n",
       "is_long                 608.379173\n",
       "total_price             161.340387\n",
       "num_riders               71.748309\n",
       "car_id_superman          57.821870\n",
       "end_time_hour_1          37.260980\n",
       "region_south sf          20.086362\n",
       "is_justice_league        19.763780\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.rating\n",
    "X = df.drop(['rating', 'rating_normed', 'top_rating', 'bad_rating'], 1)\n",
    "model = SelectKBest(chi2).fit(X, y)\n",
    "importances = model.scores_\n",
    "pd.Series(importances, X.columns).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_sec        0.145298\n",
       "total_price         0.063506\n",
       "price               0.058140\n",
       "num_riders          0.039479\n",
       "is_long             0.031658\n",
       "is_avenger          0.018490\n",
       "is_day              0.015206\n",
       "car_id_spiderman    0.013156\n",
       "car_id_hulk         0.012699\n",
       "car_id_ironman      0.012618\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "y = df.rating\n",
    "X = df.drop(['rating', 'rating_normed', 'top_rating', 'bad_rating'], 1)\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_  \n",
    "pd.Series(importances, X.columns).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_long              0.177898\n",
       "rating               0.160377\n",
       "duration_sec         0.102351\n",
       "num_riders           0.065779\n",
       "car_id_superman      0.064416\n",
       "bad_rating           0.063713\n",
       "total_price          0.050736\n",
       "is_justice_league    0.025641\n",
       "start_time_hour_9    0.022976\n",
       "user_id_1            0.015607\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.has_near_miss\n",
    "X = df.drop(['num_near_misses', 'has_near_miss', 'rating_normed'], 1)\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_  \n",
    "pd.Series(importances, X.columns).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
